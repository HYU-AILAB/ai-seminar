# title
SYNTHESIZER : Rethinking Self-Attention in Transformer Models
## Paper

- link : [Paper](https://arxiv.org/pdf/2005.00743.pdf)

- 키워드 : SYNTEHSIZER, Self-attenion

- 한줄 소개 : self-attention을 대체할 fucntion 소개

### References

- [reniew's blog](https://reniew.github.io/43/)
- [platform tech team](https://medium.com/platfarm/%EC%96%B4%ED%85%90%EC%85%98-%EB%A9%94%EC%BB%A4%EB%8B%88%EC%A6%98%EA%B3%BC-transfomer-self-attention-842498fd3225)
- [딥 러닝을 이용한 자연어 처리 입문](https://wikidocs.net/22893)


